# Data Engineering ‚Äì Pipelines, Big Data & Data Warehousing

Este repositorio contiene el material desarrollado durante la asignatura de **Data Engineering**, enfocada en el **dise√±o, construcci√≥n y orquestaci√≥n de pipelines de datos**, aplicando buenas pr√°cticas de ingenier√≠a de datos sobre diferentes fuentes, vol√∫menes y arquitecturas.

A lo largo del curso se trabajaron casos pr√°cticos que abarcan desde la **ingesti√≥n de datos**, su **transformaci√≥n**, hasta el **almacenamiento y an√°lisis** en sistemas anal√≠ticos.

## Contenido del repositorio

El repositorio est√° organizado por **componentes clave de un sistema de Data Engineering**:

### 1. Fuentes de Datos
- Consumo de datos desde APIs externas.
- Extracci√≥n de datos estructurados y semi-estructurados.
- Casos pr√°cticos de ingesta de datos.

> Carpeta: `Fuentes de Datos/`  

### 2. Carga de Archivos
- Procesamiento de archivos CSV / PARQUET.
- Multhitreading
- Multiprocessing

> Carpeta: `Carga de Archivos/`

### 3. Transformaci√≥n de Datos
- Limpieza, normalizaci√≥n e imputaci√≥n de datos.
- Aplicaci√≥n de reglas de negocio.
- Transformaciones para consumo anal√≠tico.

> Carpeta: `Transformaci√≥n de Datos/`

### 4. ETL (Extract, Transform, Load)
- Dise√±o e implementaci√≥n de pipelines ETL.
- Orquestaci√≥n de procesos.
- Manejo de datos faltantes e imputaci√≥n.

> Carpeta: `ETL/`

### üè¢ 5. Data Warehouse (DW)
- Modelado dimensional.
- Esquemas estrella.
- Preparaci√≥n de datos para an√°lisis y reporting.

> Carpeta: `DW/`

### 6. Big Data
- Procesamiento distribuido de datos.
- Uso de **PySpark** para an√°lisis a gran escala.
- Integraci√≥n con **Databricks**.
- Operaciones sobre dataframes distribuidos.

> Carpeta: `Big Data/`

### 7. Bases de Datos
- Conexi√≥n y consulta a bases de datos.
- Uso de SQL en flujos de datos.
- Casos pr√°cticos de scraping y almacenamiento.
- MongoDB

> Carpeta: `Bases de Datos/`  

## Tecnolog√≠as y herramientas utilizadas

- **Python**
- **SQL**
- **PySpark**
- **Databricks**
- **Pandas**
- **APIs REST**
- **Jupyter Notebook / VS Code**

## Objetivo del repositorio

El objetivo del repositorio es **demostrar la implementaci√≥n completa de flujos de datos**, aplicando conceptos fundamentales de Data Engineering como:

- Ingesti√≥n de datos
- Transformaci√≥n y calidad de datos
- Orquestaci√≥n ETL
- Almacenamiento anal√≠tico
- Procesamiento Big Data

Adem√°s, sirve como:
- Evidencia acad√©mica del curso
- Base para proyectos reales
- Portafolio de Data Engineering

---

üìå *Repositorio desarrollado con fines acad√©micos como parte del curso de Data Engineering.*
